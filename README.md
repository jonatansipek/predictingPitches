Unlocking Shark Tank: Predicting pitch outcomes using a multimodal approach

Acquiring funding for a startup venture is a critical yet challenging endeavor. Funding success often hinges on effectively pitching a business idea to potential investors. Understanding the multimodal cues influencing investment decision-making can significantly enhance entrepreneurs' persuasive skills and provide valuable insights for investors and entrepreneurs. Previous research on predicting investment decisions in entrepreneurial pitches has primarily focused on unimodal behavioral cues, emphasizing vocal features. To address this gap, this study combines visual, verbal, and vocal cues with a unique emphasis on body language to predict pitch outcomes. By implementing a robust feature extraction framework for video data and utilizing interpretable machine learning models, this research aims to further enhance the understanding of investor decision-making processes. Our findings indicate that a multimodal approach outperforms unimodal methods in predicting pitch success, underscoring the importance of the interplay between all modalities in achieving successful pitches. Displaying a positive facial expression, using a high level of gestures, and maintaining low variation in vocal pitch have the greatest impact on the likelihood of securing a deal. The best-performing multimodal model achieved an accuracy of 62.8% and an F1 score of 0.77.
